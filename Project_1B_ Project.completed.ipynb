{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python packages \n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "import decimal\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/home/event_data/2018-11-20-events.csv\n",
      "/workspace/home/event_data/2018-11-12-events.csv\n",
      "/workspace/home/event_data/2018-11-04-events.csv\n",
      "/workspace/home/event_data/2018-11-10-events.csv\n",
      "/workspace/home/event_data/2018-11-06-events.csv\n",
      "/workspace/home/event_data/2018-11-09-events.csv\n",
      "/workspace/home/event_data/2018-11-05-events.csv\n",
      "/workspace/home/event_data/2018-11-17-events.csv\n",
      "/workspace/home/event_data/2018-11-30-events.csv\n",
      "/workspace/home/event_data/2018-11-29-events.csv\n",
      "/workspace/home/event_data/2018-11-16-events.csv\n",
      "/workspace/home/event_data/2018-11-26-events.csv\n",
      "/workspace/home/event_data/2018-11-22-events.csv\n",
      "/workspace/home/event_data/2018-11-13-events.csv\n",
      "/workspace/home/event_data/2018-11-25-events.csv\n",
      "/workspace/home/event_data/2018-11-21-events.csv\n",
      "/workspace/home/event_data/2018-11-11-events.csv\n",
      "/workspace/home/event_data/2018-11-02-events.csv\n",
      "/workspace/home/event_data/2018-11-14-events.csv\n",
      "/workspace/home/event_data/2018-11-03-events.csv\n",
      "/workspace/home/event_data/2018-11-28-events.csv\n",
      "/workspace/home/event_data/2018-11-08-events.csv\n",
      "/workspace/home/event_data/2018-11-18-events.csv\n",
      "/workspace/home/event_data/2018-11-15-events.csv\n",
      "/workspace/home/event_data/2018-11-24-events.csv\n",
      "/workspace/home/event_data/2018-11-23-events.csv\n",
      "/workspace/home/event_data/2018-11-07-events.csv\n",
      "/workspace/home/event_data/2018-11-27-events.csv\n",
      "/workspace/home/event_data/2018-11-19-events.csv\n",
      "/workspace/home/event_data/2018-11-01-events.csv\n"
     ]
    }
   ],
   "source": [
    "# checking your current working directory\n",
    "#print(os.getcwd())\n",
    "\n",
    "# Get your current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Create a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    \n",
    "# join the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))\n",
    "    print(*file_path_list, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiating an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# for every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "\n",
    "# reading csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # creating a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "        \n",
    " # extracting each data row one by one and append it        \n",
    "        for line in csvreader:\n",
    "            #print(line)\n",
    "            full_data_rows_list.append(line) \n",
    "            \n",
    "# uncomment the code below if you would like to get total number of rows \n",
    "#print(len(full_data_rows_list))\n",
    "# uncomment the code below if you would like to check to see what the list of event data rows will look like\n",
    "#print(full_data_rows_list)\n",
    "\n",
    "# creating a smaller event data csv file called event_datafile_full csv that will be used to insert data into the \\\n",
    "# Apache Cassandra tables\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n"
     ]
    }
   ],
   "source": [
    "# check the number of rows in your csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should make a connection to a Cassandra instance your local machine \n",
    "# (127.0.0.1)\n",
    "\n",
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster(['127.0.0.1'])\n",
    "\n",
    "# To establish connection and begin executing queries, need a session\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Keyspace T\n",
    "try:\n",
    "    session.execute(\"\"\"\n",
    "    CREATE KEYSPACE IF NOT EXISTS t \n",
    "    WITH REPLICATION = \n",
    "    { 'class' : 'SimpleStrategy', 'replication_factor' : 1 }\"\"\"\n",
    ")\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set KEYSPACE to the keyspace specified above\n",
    "try:\n",
    "    session.set_keyspace('t')\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CODE FOR QUESTION 1 FOR THE DATA: \n",
    "#### Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "COMPOSITE KEY:\n",
    "Using column \"iteminsession\" as the partition key will distribute data items equaly in nodes for small amount of session items. \n",
    "Using clustering column \"sessionid\" will allow us to use it in the WHERE clause and insure the primary key is unique\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Table creation and data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = \"CREATE TABLE IF NOT EXISTS song_length_sessionitem \" \n",
    "query1 = query1 + \"(iteminsession int, sessionid int, artist text, song text, length decimal, PRIMARY KEY(iteminsession, sessionid))\"\n",
    "try:\n",
    "    session.execute(query1)\n",
    "except Exception as e:\n",
    "    print(e)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file = 'event_datafile_new.csv'\n",
    "##INSERT statements\n",
    "query = \"INSERT INTO song_length_sessionitem (iteminsession, sessionid, artist, song, length)\"  \n",
    "query = query + \" VALUES (%s, %s, %s, %s, %s)\"\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        ## Column element assigned for each column in the INSERT statement.\n",
    "        ## see above insert statements for column name mapping  \n",
    "        session.execute(query, (int(line[3]), int(line[8]), line[0], line[9], decimal.Decimal(line[5])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Do a SELECT to verify that the data have been inserted into table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Faithless</td>\n",
       "      <td>Music Matters (Mark Knight Dub)</td>\n",
       "      <td>495.3073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SELECT statement to verify the data\n",
    "query = \"SELECT artist, song, length FROM song_length_sessionitem WHERE iteminsession = 4 and sessionid=338\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "df = pd.DataFrame(list(rows))\n",
    "HTML(df.to_html(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CODE FOR QUESTION 2 FOR THE DATA: \n",
    "#### Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "COMPOSITE KEY:\n",
    "Partition is by \"userid, sessionid\" on nodes for our small amount of data and clustering column \"itemsession\" is used to display in ascending order, so we are satisfying the \"itemsession\" ordering request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Table creation and data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "query2 = \"CREATE TABLE IF NOT EXISTS song_playlist_session \" \n",
    "query2 = query2 + \"(userid int, sessionid int, iteminsession int, artist text, song text, user text, PRIMARY KEY((userid,sessionid), iteminsession))\"\n",
    "try:\n",
    "    session.execute(query2)\n",
    "except Exception as e:\n",
    "    print(e)       \n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'event_datafile_new.csv'\n",
    "##INSERT statements\n",
    "query = \"INSERT INTO song_playlist_session (userid, sessionid, iteminsession, artist, song, user)\"  \n",
    "query = query + \" VALUES (%s, %s, %s, %s, %s, %s)\"\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        ## Column element assigned for each column in the INSERT statement.\n",
    "        ##see above insert statements for column name mapping \n",
    "        session.execute(query, (int(line[10]), int(line[8]), int(line[3]), line[0], line[9], (line[1]+' '+ line[4])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Do a SELECT to verify that the data have been inserted into table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Down To The Bone</td>\n",
       "      <td>Keep On Keepin' On</td>\n",
       "      <td>Sylvie Cruz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Three Drives</td>\n",
       "      <td>Greece 2000</td>\n",
       "      <td>Sylvie Cruz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Sebastien Tellier</td>\n",
       "      <td>Kilometer</td>\n",
       "      <td>Sylvie Cruz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Lonnie Gordon</td>\n",
       "      <td>Catch You Baby (Steve Pitron &amp; Max Sanna Radio...</td>\n",
       "      <td>Sylvie Cruz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SELECT statement to verify the data\n",
    "query = \"SELECT artist, song, user FROM song_playlist_session WHERE userid=10 and sessionid=182\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "df = pd.DataFrame(list(rows))\n",
    "HTML(df.to_html(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CODE FOR QUESTION 3 FOR THE DATA: \n",
    "#### Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "COMPOSITE KEY:\n",
    "Partition is by \"song\" on nodes for our small amount of data and clustering column \"userid\" insure a unique primary key for the specific question 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Table creation and data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "query3 = \"CREATE TABLE IF NOT EXISTS song_listened_by_user \" \n",
    "query3 = query3 + \"(song text, userid int, user text, PRIMARY KEY(song, userid))\"\n",
    "try:\n",
    "    session.execute(query3)\n",
    "except Exception as e:\n",
    "    print(e)       \n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'event_datafile_new.csv'\n",
    "##INSERT statements\n",
    "query = \"INSERT INTO song_listened_by_user (song, userid, user)\"  \n",
    "query = query + \" VALUES (%s, %s, %s)\"\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        ## Column element assigned for each column in the INSERT statement.\n",
    "        ##see above insert statements for column name mapping \n",
    "        session.execute(query, (line[9], int(line[10]), (line[1]+' '+ line[4])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Do a SELECT to verify that the data have been inserted into table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Jacqueline Lynch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Tegan Levine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Sara Johnson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SELECT statement to verify the data\n",
    "query = \"SELECT user FROM song_listened_by_user WHERE song='All Hands Against His Own'\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "df = pd.DataFrame(list(rows))\n",
    "HTML(df.to_html(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dropping the table before closing out the sessions\n",
    "try:\n",
    "   session.execute('DROP TABLE song_length_sessionitem')\n",
    "   session.execute('DROP TABLE song_playlist_session')\n",
    "   session.execute('DROP TABLE song_listened_by_user')\n",
    "except Exception as e:\n",
    "    print(e)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close the session and cluster connection¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
